{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from keras.callbacks import (TensorBoard,\n",
    "                             EarlyStopping,\n",
    "                             ReduceLROnPlateau,\n",
    "                             CSVLogger)\n",
    "from keras.layers import Conv3D, Dense, Reshape, Add, Input\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical, multi_gpu_model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from capsulenet import margin_loss\n",
    "from capsulelayers import CapsuleLayer, PrimaryCap, Length, Mask, Conv3DCap\n",
    "\n",
    "from data import load_data\n",
    "from utils import upsample_classes, stratified_shuffle\n",
    "from results import process_results\n",
    "\n",
    "\n",
    "NAME= 'ModelNet40'\n",
    "NUM_EPOCHS = 25\n",
    "\n",
    "# Load the data\n",
    "(x_train, y_train), (x_test, y_test), target_names = load_data(NAME)\n",
    "x_train, y_train, x_val, y_val = stratified_shuffle(x_train, y_train, test_size=.1)\n",
    "x_train, y_train = upsample_classes(x_train, y_train)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_val = to_categorical(y_val)\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = \\\n",
    "    x_train[:256], y_train[:256], x_val[:100], y_val[:100], x_test[:100], y_test[:100]\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "n_class = y_test.shape[1]\n",
    "input_shape = (30, 30, 30, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_sub_capsule=16\n",
    "dim_primary_capsule=5\n",
    "n_channels=8\n",
    "primary_cap_kernel_size=9\n",
    "first_layer_kernel_size=9\n",
    "conv_layer_filters=48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(shape=input_shape)\n",
    "conv1 = Conv3D(filters=conv_layer_filters, kernel_size=3, strides=1,\n",
    "                              padding='valid', activation='relu', name='conv1')(x)\n",
    "primarycaps = Conv3DCap(conv1, dim_capsule=4, n_channels=4,\n",
    "                        kernel_size=3, strides=2, padding='valid',\n",
    "                        name='primarycap_conv3d')\n",
    "secondary_caps = PrimaryCap(primarycaps, dim_capsule=4, n_channels=4,\n",
    "                            kernel_size=2, strides=1, padding='valid',\n",
    "                            name='secondarycap_conv3d')\n",
    "sub_caps = CapsuleLayer(num_capsule=n_class, dim_capsule=dim_sub_capsule,\n",
    "                                                 routings=3, name='sub_caps')(secondary_caps)\n",
    "\n",
    "out_caps = Length(name='capsnet')(sub_caps)\n",
    "\n",
    "# Decoder network\n",
    "y = Input(shape=(n_class,))\n",
    "masked_by_y = Mask()([sub_caps, y])\n",
    "masked = Mask()(sub_caps)\n",
    "\n",
    "# shared decoder model in training and prediction\n",
    "decoder = Sequential(name='decoder')\n",
    "decoder.add(Dense(512, activation='relu',\n",
    "                  input_dim=dim_sub_capsule*n_class))\n",
    "decoder.add(Dense(1024, activation='relu'))\n",
    "decoder.add(Dense(np.prod(input_shape), activation='sigmoid'))\n",
    "decoder.add(Reshape(target_shape=input_shape, name='out_recon'))\n",
    "\n",
    "\n",
    "### Models for training and evaluation (prediction and actually using)\n",
    "train_model = Model([x, y], [out_caps, decoder(masked_by_y)])\n",
    "eval_model = Model(x, [out_caps, decoder(masked)])\n",
    "\n",
    "### manipulate model can be used to visualize activation maps for specific classes\n",
    "noise = Input(shape=(n_class, dim_sub_capsule))\n",
    "noised_sub_caps = Add()([sub_caps, noise])\n",
    "masked_noised_y = Mask()([noised_sub_caps, y])\n",
    "manipulate_model = Model([x, y, noise], decoder(masked_noised_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_LR = 0.008\n",
    "lam_recon = .04\n",
    "optimizer = Adam(lr=INIT_LR)\n",
    "train_model.compile(optimizer,\n",
    "                    loss=[margin_loss, 'mse'],\n",
    "                    loss_weights=[1., lam_recon],\n",
    "                    metrics={'capsnet': 'accuracy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 256 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "256/256 [==============================] - 29s 113ms/step - loss: 0.8200 - capsnet_loss: 0.8100 - decoder_loss: 0.2492 - capsnet_acc: 0.2773 - val_loss: 0.8199 - val_capsnet_loss: 0.8100 - val_decoder_loss: 0.2477 - val_capsnet_acc: 0.0800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd2ca0f6780>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model.fit([x_train, y_train], [y_train, x_train],\n",
    "                                batch_size=32, epochs=NUM_EPOCHS,\n",
    "                                validation_data=[[x_val, y_val], [y_val, x_val]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from keras.callbacks import (TensorBoard,\n",
    "                             EarlyStopping,\n",
    "                             ReduceLROnPlateau,\n",
    "                             CSVLogger)\n",
    "from keras.layers import Conv3D, Dense, Reshape, Add, Input\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical, multi_gpu_model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from capsulenet import margin_loss\n",
    "from capsulelayers import CapsuleLayer, PrimaryCap, Length, Mask\n",
    "\n",
    "from data import load_data\n",
    "from utils import upsample_classes, stratified_shuffle\n",
    "from results import process_results\n",
    "\n",
    "\n",
    "NAME= 'ModelNet40'\n",
    "NUM_EPOCHS = 25\n",
    "\n",
    "# Load the data\n",
    "(x_train, y_train), (x_test, y_test), target_names = load_data(NAME)\n",
    "x_train, y_train, x_val, y_val = stratified_shuffle(x_train, y_train, test_size=.1)\n",
    "x_train, y_train = upsample_classes(x_train, y_train)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_val = to_categorical(y_val)\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = \\\n",
    "    x_train[:256], y_train[:256], x_val[:100], y_val[:100], x_test[:100], y_test[:100]\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "n_class = y_test.shape[1]\n",
    "input_shape = (30, 30, 30, 1)\n",
    "\n",
    "dim_sub_capsule=16\n",
    "dim_primary_capsule=5\n",
    "n_channels=8\n",
    "primary_cap_kernel_size=9\n",
    "first_layer_kernel_size=9\n",
    "conv_layer_filters=48\n",
    "\n",
    "x = Input(shape=input_shape)\n",
    "conv1 = Conv3D(filters=conv_layer_filters, kernel_size=first_layer_kernel_size, strides=1,\n",
    "                              padding='valid', activation='relu', name='conv1')(x)\n",
    "primarycaps = PrimaryCap(conv1, dim_capsule=dim_primary_capsule, n_channels=n_channels,\n",
    "                                                  kernel_size=primary_cap_kernel_size, strides=2, padding='valid',\n",
    "                                                  name='primarycap_conv3d')\n",
    "secondary_caps = PrimaryCap(primarycaps, dim_capsule=8, n_channels=4,\n",
    "                            kernel_size=2, strides=1, padding='valid',\n",
    "                            name='secondarycap_conv3d')\n",
    "sub_caps = CapsuleLayer(num_capsule=n_class, dim_capsule=dim_sub_capsule,\n",
    "                                                 routings=3, name='sub_caps')(secondary_caps)\n",
    "# sub_caps = CapsuleLayer(num_capsule=n_class, dim_capsule=dim_sub_capsule,\n",
    "#                                                  routings=3, name='sub_caps')(primarycaps)\n",
    "out_caps = Length(name='capsnet')(sub_caps)\n",
    "\n",
    "# Decoder network\n",
    "y = Input(shape=(n_class,))\n",
    "masked_by_y = Mask()([sub_caps, y])\n",
    "masked = Mask()(sub_caps)\n",
    "\n",
    "# shared decoder model in training and prediction\n",
    "decoder = Sequential(name='decoder')\n",
    "decoder.add(Dense(512, activation='relu',\n",
    "                  input_dim=dim_sub_capsule*n_class))\n",
    "decoder.add(Dense(1024, activation='relu'))\n",
    "decoder.add(Dense(np.prod(input_shape), activation='sigmoid'))\n",
    "decoder.add(Reshape(target_shape=input_shape, name='out_recon'))\n",
    "\n",
    "\n",
    "### Models for training and evaluation (prediction and actually using)\n",
    "train_model = Model([x, y], [out_caps, decoder(masked_by_y)])\n",
    "eval_model = Model(x, [out_caps, decoder(masked)])\n",
    "\n",
    "### manipulate model can be used to visualize activation maps for specific classes\n",
    "noise = Input(shape=(n_class, dim_sub_capsule))\n",
    "noised_sub_caps = Add()([sub_caps, noise])\n",
    "masked_noised_y = Mask()([noised_sub_caps, y])\n",
    "manipulate_model = Model([x, y, noise], decoder(masked_noised_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
